{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e773e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: tracker in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.1.1)\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "!pip install opencv-python\n",
    "!pip install tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866350d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import collections\n",
    "import numpy as np\n",
    "from tracker import *\n",
    "\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1517a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h, index = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 25:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    # print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id, index])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count, index])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id, index = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids\n",
    "\n",
    "\n",
    "\n",
    "def ad(a, b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898e8cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tracker\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "# Initialize the videocapture object\n",
    "cap = cv2.VideoCapture('testcase.MP4')\n",
    "input_size = 320\n",
    "\n",
    "# Detection confidence threshold\n",
    "confThreshold = 0.2\n",
    "nmsThreshold = 0.2\n",
    "\n",
    "font_color = (0, 0, 255)\n",
    "font_size = 0.5\n",
    "font_thickness = 2\n",
    "\n",
    "# Middle cross line position\n",
    "middle_line_position = 250  \n",
    "up_line_position = middle_line_position - 5\n",
    "down_line_position = middle_line_position + 5\n",
    "\n",
    "# List for store vehicle count information\n",
    "temp_up_list = []\n",
    "temp_down_list = []\n",
    "vehicle_list =[]\n",
    "counts = [0, 0, 0, 0, 0]\n",
    "up_list = [0, 0, 0, 0, 0]\n",
    "down_list = [0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450c6a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "80\n",
      "['Auto']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Store Coco Names in a list\n",
    "classesFile = \"coco.names\"\n",
    "classNames = open(classesFile).read().strip().split('\\n')\n",
    "print(classNames)\n",
    "print(len(classNames))\n",
    "\n",
    "autoFile = \"auto.names\"\n",
    "autoNames = open(autoFile).read().strip().split('\\n')\n",
    "print(autoNames)\n",
    "print(len(autoNames))\n",
    "\n",
    "\n",
    "\n",
    "# class index for our required detection classes\n",
    "required_class_index = [2, 3, 5, 7]\n",
    "auto_class_index = [0]\n",
    "\n",
    "detected_classNames = []\n",
    "\n",
    "## Model Files\n",
    "modelConfiguration = 'yolov3-320.cfg'\n",
    "modelWeigheights = 'yolov3-320.weights'\n",
    "\n",
    "autoConfiguration = 'yolov3_custom.cfg'\n",
    "autoWeigheights = 'yolov3_custom_2000.weights'\n",
    "\n",
    "# configure the network model\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeigheights)\n",
    "\n",
    "net1 = cv2.dnn.readNetFromDarknet(autoConfiguration, autoWeigheights)\n",
    "\n",
    "# Configure the network backend\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "net1.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net1.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Define random colour for each class\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
    "\n",
    "np.random.seed(42)\n",
    "colorsauto = np.random.randint(0, 255, size=(len(autoNames), 3), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23c51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the center of a rectangle\n",
    "def find_center(x, y, w, h):\n",
    "    x1=int(w/2)\n",
    "    y1=int(h/2)\n",
    "    cx = x+x1\n",
    "    cy=y+y1\n",
    "    return cx, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06dff582",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for count vehicle\n",
    "def count_vehicle(box_id, img):\n",
    "\n",
    "    x, y, w, h, id, index = box_id\n",
    "\n",
    "    # Find the center of the rectangle for detection\n",
    "    center = find_center(x, y, w, h)\n",
    "    ix, iy = center\n",
    "#single\n",
    "#     if id not in vehicle_list:\n",
    "#         vehicle_list.append(id)\n",
    "#         counts[index]+=1\n",
    "    \n",
    "    if (iy > up_line_position) and (iy < middle_line_position):\n",
    "        if id not in temp_up_list:\n",
    "            temp_up_list.append(id)\n",
    "            print(\"tup\",id,temp_up_list)\n",
    "            up_list[index] = up_list[index]+1\n",
    "\n",
    "    elif (iy < down_line_position) and (iy > middle_line_position):\n",
    "        if id not in temp_down_list:\n",
    "            temp_down_list.append(id)\n",
    "            print(\"tdown\",id,temp_down_list)\n",
    "            down_list[index] = down_list[index] + 1\n",
    "            \n",
    "    elif iy < up_line_position:\n",
    "        if id in temp_down_list:\n",
    "            temp_down_list.remove(id)\n",
    "            print(\"up\",id,index)\n",
    "            up_list[index] = up_list[index]+1\n",
    "\n",
    "    elif iy > down_line_position:\n",
    "        if id in temp_up_list:\n",
    "            temp_up_list.remove(id)\n",
    "            print(\"down\",id,index)\n",
    "            down_list[index] = down_list[index] + 1\n",
    "\n",
    "    # Draw circle in the middle of the rectangle\n",
    "    cv2.circle(img, center, 2, (0, 0, 255), -1)  # end here\n",
    "#     print(up_list, down_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663131cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the detected objects from the network output\n",
    "def postProcess(outputs,img,auto):\n",
    "    global detected_classNames \n",
    "    height, width = img.shape[:2]\n",
    "    boxes = []\n",
    "    classIds = []\n",
    "    confidence_scores = []\n",
    "    detection = []\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if not auto:\n",
    "                if classId in required_class_index:\n",
    "                    if confidence > confThreshold:\n",
    "#                         print(classId,\"vehicle\")\n",
    "                        w,h = int(det[2]*width) , int(det[3]*height)\n",
    "                        x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
    "                        boxes.append([x,y,w,h])\n",
    "                        classIds.append(classId)\n",
    "                        confidence_scores.append(float(confidence))\n",
    "            else:\n",
    "                if classId in auto_class_index:\n",
    "                    if confidence > confThreshold:\n",
    "#                         print(classId,\"auto\")\n",
    "                        w,h = int(det[2]*width) , int(det[3]*height)\n",
    "                        x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
    "                        boxes.append([x,y,w,h])\n",
    "                        classIds.append(classId)\n",
    "                        confidence_scores.append(float(confidence))\n",
    "                \n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
    "    # print(classIds)\n",
    "    if len(indices)>0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "            # print(x,y,w,h)\n",
    "            \n",
    "            if not auto:\n",
    "                color = [int(c) for c in colors[classIds[i]]]\n",
    "                name = classNames[classIds[i]]\n",
    "#                 print(name)\n",
    "                detected_classNames.append(name)\n",
    "                \n",
    "                # Draw classname and confidence score \n",
    "                cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n",
    "                          (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "                # Draw bounding rectangle\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "                detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n",
    "\n",
    "            else:\n",
    "                colorauto = [int(c) for c in colorsauto[classIds[i]]]\n",
    "                name = autoNames[classIds[i]]\n",
    "#                 print(name)\n",
    "                detected_classNames.append(name)\n",
    "\n",
    "\n",
    "                    # Draw classname and confidence score \n",
    "                cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n",
    "                          (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colorauto, 1)\n",
    "\n",
    "                # Draw bounding rectangle\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), colorauto, 1)\n",
    "                detection.append([x, y, w, h, len(required_class_index) + auto_class_index.index(classIds[i])])\n",
    "#                 print(\"auto\",[x, y, w, h, len(required_class_index) + auto_class_index.index(classIds[i])])\n",
    "                \n",
    "            # Update the tracker for each object\n",
    "        boxes_ids = tracker.update(detection)\n",
    "#         print(\"box_ids\",boxes_ids)\n",
    "        for box_id in boxes_ids:\n",
    "#             print(\"id\",box_id)\n",
    "            count_vehicle(box_id, img)        \n",
    "                \n",
    "#             # Draw classname and confidence score \n",
    "#             cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n",
    "#                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "#             # Draw bounding rectangle\n",
    "#             cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "#             detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061ef35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realTime():\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        try:\n",
    "            img = cv2.resize(img,(0,0),None,0.5,0.5)\n",
    "            ih, iw, channels = img.shape\n",
    "            blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "            # Set the input of the network\n",
    "            net1.setInput(blob)\n",
    "            layersNames1 = net1.getLayerNames()\n",
    "#             print(layersNames)\n",
    "            outputNames1 = [(layersNames1[i- 1]) for i in net1.getUnconnectedOutLayers()]\n",
    "#             print(outputNames)\n",
    "            # Feed data to the network\n",
    "            outputs1 = net1.forward(outputNames1)\n",
    "\n",
    "            # Find the objects from the network output\n",
    "            postProcess(outputs1,img,True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Set the input of the network\n",
    "            net.setInput(blob)\n",
    "            layersNames = net.getLayerNames()\n",
    "#             print(layersNames)\n",
    "            outputNames = [(layersNames[i- 1]) for i in net.getUnconnectedOutLayers()]\n",
    "#             print(outputNames)\n",
    "            # Feed data to the network\n",
    "            outputs = net.forward(outputNames)\n",
    "\n",
    "            # Find the objects from the network output\n",
    "            postProcess(outputs,img,False)\n",
    "            \n",
    "            # Draw the crossing lines\n",
    "            cv2.line(img, (0, middle_line_position), (iw, middle_line_position), (255, 0, 255), 2)\n",
    "            cv2.line(img, (0, up_line_position), (iw, up_line_position), (0, 0, 255), 2)\n",
    "            cv2.line(img, (0, down_line_position), (iw, down_line_position), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw counting texts in the frame\n",
    "            cv2.putText(img, \"Count\", (110, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "#          cv2.putText(img, \"Down\", (160, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "            cv2.putText(img, \"Car:        \"+ str(down_list[0]), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "            cv2.putText(img, \"Motorbike:  \"+ str(down_list[1]), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "            cv2.putText(img, \"Bus:        \"+ str(down_list[2]), (20, 80), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "            cv2.putText(img, \"Truck:      \"+ str(down_list[3]), (20, 100), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "            cv2.putText(img, \"Auto:       \"+ str(down_list[4]), (20, 120), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "\n",
    "#single lane\n",
    "#             cv2.putText(img, \"Car:        \"+str(counts[0]),(20, 40), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "#             cv2.putText(img, \"Motorbike:  \"+str(counts[1]),(20, 60), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "#             cv2.putText(img, \"Bus:        \"+str(counts[2]),(20, 80), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "#             cv2.putText(img, \"Truck:      \"+str(counts[3]),(20, 100), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "#             cv2.putText(img, \"Auto:      \"+str(counts[4]), (20, 120),cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Show the frames\n",
    "            cv2.imshow('Output', img)\n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            \n",
    "    # realese the capture object and destroy all active windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e948cb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tdown 5 [5]\n",
      "tdown 8 [5, 8]\n",
      "tup 8 [8]\n",
      "tup 5 [8, 5]\n",
      "up 5 1\n",
      "up 8 1\n",
      "tdown 9 [9]\n",
      "tup 9 [8, 5, 9]\n",
      "up 9 0\n",
      "tdown 38 [38]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mrealTime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mrealTime\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m             outputNames \u001b[38;5;241m=\u001b[39m [(layersNames[i\u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mgetUnconnectedOutLayers()]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#             print(outputNames)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;66;03m# Feed data to the network\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputNames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;66;03m# Find the objects from the network output\u001b[39;00m\n\u001b[0;32m     33\u001b[0m             postProcess(outputs,img,\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    realTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb31b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc34ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711393a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
